{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Pretraining on Unlabeled Data\n",
    "\n",
    "> LLMs from Scratch\n",
    "\n",
    "- Minjae Gwon\n",
    "  <minjae.gwon@postech.ac.kr>\n",
    "  <https://bxta.kr>\n",
    "\n",
    "- ML Lab\n",
    "  <https://ml.postech.ac.kr>\n",
    "\n",
    "- CompSec Lab\n",
    "  <https://compsec.postech.ac.kr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Evaluating generative text models\n",
    "\n",
    "### 5.1.1 Using GPT to generate text\n",
    "\n",
    "- 텍스트 생성 과정을 간단히 복습하기 위해 LLM을 셋업.\n",
    "  - 트레이닝에 필요한 컴퓨팅 자원을 줄이기 위해 이전 장에 비해 context length를 줄였음.\n",
    "  - 최근 LLMs는 드롭아웃을 사용하지 않는 경향이 잇음.\n",
    "  - 최근 LLMs는 bias vector를 사용하지 않는 경향이 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from llm_from_scratch.chapter_05.lib import GPTConfig, GPTModel\n",
    "\n",
    "GPT_CONFIG_124M: GPTConfig = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False,\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `GPTModel`을 이용해서 텍스트를 생성해보자.\n",
    "\n",
    "![](https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/gpt-process.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from tiktoken import Encoding\n",
    "from torch import Tensor\n",
    "\n",
    "from llm_from_scratch.chapter_05.lib import generate_text_simple\n",
    "\n",
    "\n",
    "def text_to_token_ids(text: str, tokenizer: Encoding):\n",
    "    encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "\n",
    "def token_ids_to_text(token_ids: Tensor, tokenizer: Encoding):\n",
    "    flat = token_ids.squeeze(0)  # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델이 트레이닝되지 않았기 때문에, 무의미한 텍스트가 생성됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 Calculating the Text Generation Loss\n",
    "\n",
    "- \"의미 있는\" 텍스트를 생성하기 위한 기준에 대해 알아볼 것임.\n",
    "- 2개의 트레이닝 example로 이루어진 `inputs` 텐서와 그에 상응하는 `targets` 텐서가 있다고 해보자.\n",
    "  - `targets` 텐서는 `inputs` 텐서를 한 칸 민 형태를 가지고 있음. (Chapter 2 참조)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(\n",
    "    [[16833, 3626, 6100], [40, 1107, 588]]\n",
    ")  # [\"every effort moves\", \"I really like\"]\n",
    "\n",
    "targets = torch.tensor(\n",
    "    [[3626, 6100, 345], [1107, 588, 11311]]\n",
    ")  # [\" effort moves you\", \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `inputs`를 모델에 넣으면 우리는 `logits` 텐서를 얻게 됨.\n",
    "- 이를 `softmax` 함수에 넣어서 `logits` 텐서를 확률 텐서로 변환할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probabilities = torch.softmax(logits, dim=-1)  # Probability of each token in vocabulary\n",
    "\n",
    "print(probabilities.shape)  # Shape: (batch_size, num_tokens, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `argmax`를 이용해서 확률 scores를 predicted token IDs로 변환할 수 있음.\n",
    "  - `argmax`는 가장 높은 확률을 가지는 token ID를 선택함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probabilities, dim=-1, keepdim=True)\n",
    "\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 하지만 모델이 트레이닝 되어 있지 않기 때문에 `targets`와는 다소 다른 token IDs가 생성된 모습을 확인할 수 있음.\n",
    "- 모델을 트레이닝 하기 위해서는 생성된 결과가 `targets`와 얼마나 멀리 떨어져 있는지를 알아야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `target`에 상응하는 확률은 아래와 같음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4540e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probabilities_1 = probabilities[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probabilities_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probabilities_2 = probabilities[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probabilities_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이때 우리의 목표는 위의 각 확률을 1에 가깝게 최대화하는 것이고, log를 취해서 계산할 것임.\n",
    "    - 수학적 최적화에서 확률 점수의 로그를 최대화하는 것이 더 쉬운 이유:\n",
    "        - **곱셈을 덧셈으로 변환**: 곱셈 연산을 덧셈 연산으로 변환하여 계산을 간단하게 만듦.\n",
    "        - **수치적 안정성**: 작은 확률 값으로 인한 언더플로우 문제를 피할 수 있음.\n",
    "        - **미분의 간편성**: 로그 함수는 미분하기 더 쉬움.\n",
    "        - **오목성**: 로그 함수는 오목(convex)하여 최적화 문제를 더 쉽게 해결할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log probabilities: tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "log_probabilities = torch.log(\n",
    "    torch.cat((target_probabilities_1, target_probabilities_2))\n",
    ")\n",
    "\n",
    "print(\"Log probabilities:\", log_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이들의 평균을 구하면 아래와 같음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average log probability: tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "average_log_probability = torch.mean(log_probabilities)\n",
    "\n",
    "print(\"Average log probability:\", average_log_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \"각 확률을 1에 가깝게 최대화 하는\" 목표는 \"위의 평균값을 0에 가깝게 만드는 것\"과 동일한 문제로 변환됨.\n",
    "\n",
    "- 딥러닝에서는 average log-probability를 최대화하는 것이 아니라, negative log-likelihood를 최소화하는 것이 일반적임.\n",
    "- 즉, 위에서 구한 -10.7940에 -1을 곱한 값인 10.7940가 loss 값이 되며 이를 cross-entropy loss라고 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative average log probability: tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "negative_average_log_probability = -average_log_probability\n",
    "\n",
    "print(\"Negative average log probability:\", negative_average_log_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/cross-entropy.webp?123)\n",
    "\n",
    "- PyTorch에는 이전 과정을 한 번에 계산해주는 `cross_entropy`가 이미 구현되어 있음.\n",
    "- PyTorch의 `cross_entropy`를 이용하기 위해서는 텐서를 flatten된 형태로 변환해야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits shape: torch.Size([6, 50257])\n",
      "Flattened targets shape: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"Flattened logits shape:\", logits_flat.shape)\n",
    "print(\"Flattened targets shape:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `targets`는 `logits` 텐서에서 최대화하고 싶은 인덱스를 가지고 있음. \n",
    "- PyTorch의 `cross_entropy`는 내부적으로 softmax와 log-probability 계산을 적용해서 최대화하고 싶은 token indices에 대해 계산함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위에서 구한 cross-entropy loss에 exp를 취해서 perplexity를 계산할 수 있음.\n",
    "- Perplexity는 모델이 얼마나 확신을 가지고 텍스트를 생성하는지를 나타내는 지표임.\n",
    "  - Perplexity가 낮을수록 모델이 더 확신을 가지고 텍스트를 생성함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48725.8203)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3 Calculating the Training and Validation Set Losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 실습을 위해서 chapter 2에서도 사용한 \"The Verdict\"를 사용할 것임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "with urllib.request.urlopen(url) as response:\n",
    "    text_data = response.read().decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "# First 100 characters\n",
    "print(text_data[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"
     ]
    }
   ],
   "source": [
    "# Last 100 characters\n",
    "print(text_data[-99:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/batching.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위 이야기를 training set과 validation set으로 나누고 dataloader의 형태로 만들어줌."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_from_scratch.chapter_05.lib import create_dataloader_v1\n",
    "\n",
    "# Train/validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "validation_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "# Sanity check\n",
    "\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\n",
    "        \"Not enough tokens for the training loader. \"\n",
    "        \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "        \"increase the `training_ratio`\"\n",
    "    )\n",
    "\n",
    "if total_tokens * (1 - train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\n",
    "        \"Not enough tokens for the validation loader. \"\n",
    "        \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "        \"decrease the `training_ratio`\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- An optional check that the data was loaded correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in validation_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Another optional check that the token sizes are in the expected ballpark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4608\n",
      "Validation tokens: 512\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in validation_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이후 주어진 배치에서의 loss를 계산하는 함수와 전체 데이터셋에서의 loss를 계산하는 함수를 정의할 것임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor, device, nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def loss_of_batch(\n",
    "    input_batch: Tensor, target_batch: Tensor, model: nn.Module, device: device\n",
    "):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "    logits = model(input_batch)\n",
    "\n",
    "    loss = nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def loss_of_dataloader(\n",
    "    dataloader: DataLoader[tuple[Tensor, Tensor]],\n",
    "    model: nn.Module,\n",
    "    device: device,\n",
    "    num_batches: int | None = None,\n",
    "):\n",
    "    total_loss: float = 0.0\n",
    "\n",
    "    if len(dataloader) == 0:\n",
    "        return float(\"nan\")\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(dataloader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(dataloader))\n",
    "\n",
    "    for i, (input_batch, target_batch) in enumerate(dataloader):\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "\n",
    "        loss = loss_of_batch(input_batch, target_batch, model, device)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 10.987583372328016\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = loss_of_dataloader(train_loader, model, device)\n",
    "    validation_loss = loss_of_dataloader(validation_loader, model, device)\n",
    "\n",
    "print(\"Train loss:\", train_loss)\n",
    "print(\"Validation loss:\", validation_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Training an LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/train-steps.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils\n",
    "from tiktoken import Encoding\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "\n",
    "def train_model_simple(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader[tuple[Tensor, Tensor]],\n",
    "    validation_loader: DataLoader[tuple[Tensor, Tensor]],\n",
    "    optimizer: Optimizer,\n",
    "    device: torch.device,\n",
    "    num_epochs: int,\n",
    "    eval_freq: float,\n",
    "    eval_iter: int,\n",
    "    start_context: str,\n",
    "    tokenizer: Encoding,\n",
    "):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses: list[float] = []\n",
    "    validation_losses: list[float] = []\n",
    "    track_tokens_seen: list[int] = []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()  # Reset loss gradients from previous batch iteration\n",
    "            loss = loss_of_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()  # Calculate loss gradients\n",
    "            optimizer.step()  # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, validation_loss = evaluate_model(\n",
    "                    model, train_loader, validation_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                validation_losses.append(validation_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(\n",
    "                    f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                    f\"Train loss {train_loss:.3f}, Val loss {validation_loss:.3f}\"\n",
    "                )\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "\n",
    "    return train_losses, validation_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def evaluate_model(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader[tuple[Tensor, Tensor]],\n",
    "    validation_loader: DataLoader[tuple[Tensor, Tensor]],\n",
    "    device: torch.device,\n",
    "    eval_iter: int,\n",
    "):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = loss_of_dataloader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = loss_of_dataloader(\n",
    "            validation_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(\n",
    "    model: nn.Module, tokenizer: Encoding, device: torch.device, start_context: str\n",
    "):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded, max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "        decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "        print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위 코드를 이용하여 트레이닝 하면 아래와 같은 결과를 얻을 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.818, Val loss 9.928\n",
      "Ep 1 (Step 000005): Train loss 8.065, Val loss 8.335\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.622, Val loss 7.051\n",
      "Ep 2 (Step 000015): Train loss 6.047, Val loss 6.600\n",
      "Every effort moves you, and,, and,,,,,,, and,.                                   \n",
      "Ep 3 (Step 000020): Train loss 5.586, Val loss 6.477\n",
      "Ep 3 (Step 000025): Train loss 5.523, Val loss 6.399\n",
      "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and\n",
      "Ep 4 (Step 000030): Train loss 5.128, Val loss 6.366\n",
      "Ep 4 (Step 000035): Train loss 4.941, Val loss 6.366\n",
      "Every effort moves you a a to the a. Gisburn, and a. Gisburn. I had the of the of the of the of the of the of the of the of the of the of the of the of the of the. I had a\n",
      "Ep 5 (Step 000040): Train loss 4.340, Val loss 6.246\n",
      "Every effort moves you, with a, in the of the picture--as of the of the of the of the picture of his of the  \"I had been. \"Oh, in the donkey--and it was a little the man of the picture of\n",
      "Ep 6 (Step 000045): Train loss 3.967, Val loss 6.181\n",
      "Ep 6 (Step 000050): Train loss 3.451, Val loss 6.155\n",
      "Every effort moves you know the \"Oh, and.  \"Oh, and in a little: \"There, and in the    \"Oh, and I had been the donkey.            \n",
      "Ep 7 (Step 000055): Train loss 3.466, Val loss 6.195\n",
      "Ep 7 (Step 000060): Train loss 2.666, Val loss 6.134\n",
      "Every effort moves you know the picture.  \"I looked he was a little the last word.           \"I he was his pictures-c.             \n",
      "Ep 8 (Step 000065): Train loss 2.208, Val loss 6.141\n",
      "Ep 8 (Step 000070): Train loss 1.879, Val loss 6.228\n",
      "Every effort moves you know,\" was not that the picture.  \"I had the last word. Gisburn's an!  \"Oh, in the moment--as Jack himself, as he was his own the donkey. \"There were days when I\n",
      "Ep 9 (Step 000075): Train loss 1.499, Val loss 6.230\n",
      "Ep 9 (Step 000080): Train loss 1.174, Val loss 6.250\n",
      "Every effort moves you know,\" was not that my hostess was \"interesting\": on that point I could have given Miss Croft the fact, with a Mrs. Gisburn's open countenance. \"It's his pictures with a \"strongest,\" she was\n",
      "Ep 10 (Step 000085): Train loss 0.901, Val loss 6.328\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"         He placed them at my elbow and as I turned, and down the room, when I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, validation_losses, tokens_seen = train_model_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    validation_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=5,\n",
    "    eval_iter=5,\n",
    "    start_context=\"Every effort moves you\",\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(\n",
    "    epochs_seen: Tensor,\n",
    "    tokens_seen: list[int],\n",
    "    train_losses: list[float],\n",
    "    validation_losses: list[float],\n",
    "):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, validation_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(\n",
    "        MaxNLocator(integer=True)\n",
    "    )  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, validation_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위의 결과를 보면 모델이 처음에는 이해할 수 없는 단어 문자열을 생성하지만, 나중에는 문법적으로 어느 정도 맞는 문장을 생성할 수 있게 됨\n",
    "- 그러나 학습 및 검증 세트 손실을 보면 모델이 overfitting되기 시작하는 것을 알 수 있음.\n",
    "  - 여기서 overfitting이 발생하는 이유는 훈련 세트가 매우 작고, 여러 번 반복해서 학습했기 때문.\n",
    "- 모델이 마지막에 작성한 몇 가지 구절을 확인해 보면, 그 구절들이 훈련 세트에 그대로 포함되어 있는 것을 발견할 수 있습니다. 이는 모델이 단순히 훈련 데이터를 암기하는 것임을 확인할 수 있음.\n",
    "- 이후에 이러한 암기를 어느 정도 완화할 수 있는 디코딩 전략을 다룰 예정임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Decoding Strategies to Control Randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `generate_text_simple` 함수를 여러 번 실행하더라도 LLM은 항상 동일한 출력을 생성함.\n",
    "- 이제 `generate_text_simple`을 수정하기 위해 두 가지 디코딩 전략을 소개함: *temperature scaling*과 *top-k* 샘플링.\n",
    "- 이를 통해 모델이 생성하는 텍스트의 무작위성과 다양성을 제어할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 Temperature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이전에는 항상 `torch.argmax`을 사용하여 가장 높은 확률을 가진 토큰을 다음 토큰으로 샘플링했음.\n",
    "- 다양성을 추가하기 위해 `torch.multinomial(probs, num_samples=1)`을 사용하여 확률 분포에서 다음 토큰을 샘플링할 수 있음.\n",
    "- 여기서 각 인덱스가 선택될 확률은 입력 텐서에서 해당 인덱스의 확률에 대응함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다음 토큰을 생성하는 과정에 대한 간단한 요약을 제공함, 예시를 위해 매우 작은 어휘를 가정함:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "from typing import cast\n",
    "\n",
    "vocabulary = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "}\n",
    "\n",
    "inverse_vocabulary = {v: k for k, v in vocabulary.items()}\n",
    "\n",
    "# Suppose input is \"every effort moves you\", and the LLM\n",
    "# returns the following logits for the next token:\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "probabilities = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = cast(int, torch.argmax(probabilities).item())\n",
    "\n",
    "# The next generated token is then as follows:\n",
    "print(inverse_vocabulary[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "next_token_id = cast(int, torch.multinomial(probabilities, num_samples=1).item())\n",
    "\n",
    "print(inverse_vocabulary[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 x closer\n",
      "2 x every\n",
      "0 x effort\n",
      "544 x forward\n",
      "2 x inches\n",
      "1 x moves\n",
      "0 x pizza\n",
      "376 x toward\n",
      "4 x you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probabilities: Tensor):\n",
    "    torch.manual_seed(123)  # Manual seed for reproducibility\n",
    "    sample = [\n",
    "        torch.multinomial(probabilities, num_samples=1).item() for _ in range(1_000)\n",
    "    ]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocabulary[i]}\")\n",
    "\n",
    "\n",
    "print_sampled_tokens(probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `torch.argmax`을 사용하여 가장 가능성 있는 토큰을 결정하는 대신, `torch.multinomial(probas, num_samples=1)`을 사용해 softmax 분포에서 샘플링하여 가장 가능성 있는 토큰을 결정함.\n",
    "- 예시를 위해, 원래 softmax 확률을 사용하여 다음 토큰을 1,000번 샘플링할 때 어떤 일이 발생하는지 살펴보겠음:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 분포와 선택 과정을 temperature scaling이라는 개념을 통해 제어할 수 있음.\n",
    "- \"Temperature scaling\"은 로짓을 0보다 큰 숫자로 나누는 것을 의미함.\n",
    "- 1보다 큰 온도는 softmax를 적용한 후 토큰 확률이 더 균일하게 분포되게 함.\n",
    "- 1보다 작은 온도는 softmax를 적용한 후 확률 분포가 더 확신 있게(더 날카롭고 뾰족하게) 만듦."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits: Tensor, temperature: float):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "\n",
    "# Temperature values\n",
    "temperatures = [1, 0.1, 5]  # Original, higher confidence, and lower confidence\n",
    "\n",
    "# Calculate scaled probabilities\n",
    "scaled_probabilities = [\n",
    "    softmax_with_temperature(next_token_logits, T) for T in temperatures\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "x = torch.arange(len(vocabulary))\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(\n",
    "        x + i * bar_width,\n",
    "        scaled_probabilities[i],\n",
    "        bar_width,\n",
    "        label=f\"Temperature = {T}\",\n",
    "    )\n",
    "\n",
    "ax.set_ylabel(\"Probability\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocabulary.keys(), rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 온도 0.1로 다시 스케일링하면 분포가 더 날카로워져 `torch.argmax`에 가까워지며, 가장 가능성 높은 단어가 거의 항상 선택되는 것을 볼 수 있음:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "992 x forward\n",
      "0 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "8 x toward\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probabilities[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The rescaled probabilities via temperature 5 are more uniformly distributed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153 x closer\n",
      "68 x every\n",
      "55 x effort\n",
      "223 x forward\n",
      "102 x inches\n",
      "50 x moves\n",
      "43 x pizza\n",
      "218 x toward\n",
      "88 x you\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probabilities[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LLM 입력이 \"every effort moves you\"인 경우, 위 접근 방식을 사용하면 가끔씩 \"every effort moves you pizza\"와 같은 말이 안 되는 텍스트가 생성될 수 있음. 이는 1000번 중 32번, 즉 3.2%의 확률로 발생함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 Top-k sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 출력의 다양성을 높이면서도 말이 안 되는 문장의 확률을 줄이기 위해, 더 높은 온도를 사용할 수 있도록 샘플링된 토큰을 상위 k개의 가장 가능성 높은 토큰으로 제한할 수 있음:\n",
    "\n",
    "![](https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/topk.webp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_positions = torch.topk(next_token_logits, top_k)\n",
    "\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    input=torch.tensor(float(\"-inf\")),\n",
    "    other=next_token_logits,\n",
    ")\n",
    "\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "top_k_probabilities = torch.softmax(new_logits, dim=0)\n",
    "print(top_k_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.3 Modifying the Text Generation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(\n",
    "    model: nn.Module,\n",
    "    token_ids: Tensor,\n",
    "    max_new_tokens: int,\n",
    "    context_size: int,\n",
    "    temperature: float = 0.0,\n",
    "    top_k: int | None = None,\n",
    "    eos_token_id: int | None = None,\n",
    "):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = token_ids[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits\n",
    "            )\n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            next_token_id = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            next_token_id = torch.argmax(\n",
    "                logits, dim=-1, keepdim=True\n",
    "            )  # (batch_size, 1)\n",
    "\n",
    "        if (\n",
    "            next_token_id == eos_token_id\n",
    "        ):  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        token_ids = torch.cat(\n",
    "            (token_ids, next_token_id), dim=1\n",
    "        )  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know began to happen a little wild--I was such a sketch of enough\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    token_ids=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4,\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
